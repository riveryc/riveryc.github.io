[{"categories":null,"content":"I like free stuff‚Ä¶ well, who doesn‚Äôt? I‚Äôm currently hosting this website with cloudflare CDN, so the certificate is free by default (Thanks so much Cloudflare!) Well, but I still prefer something in control, or maybe encrypt some data or using v2ray üòÜ Here is how to: Assuming you are using MAC, so firstly, we need to install certbot: brew install certbot Then, get the cloudflare plugin installed: pip3 install certbot-dns-cloudflare All tools have been installed! well done! To get your API key, login to your CloudFlare dashboard, go to your profile and at the bottom, click ‚ÄúView‚Äù next to ‚ÄúGlobal API key‚Äù. cloudflare - my profile\u0026ldquo;cloudflare - my profile\u0026rdquo; \" cloudflare - my profile api token \u0026 key\u0026ldquo;api token \u0026amp; key\u0026rdquo; \" api token \u0026 key OK, next, we need to let cloudflare know who are we when we running the certbot to gain a new certificate: # Create a folder as work folder mkdir ~/certbot # Create credential file echo \"# Cloudflare API credentials used by Certbot dns_cloudflare_email = \u003cYour Email address as username in Cloudflare\u003e dns_cloudflare_api_key = \u003cYour api token\u003e \" \u003e ~/certbot/cloudflare.ini Please note, this IS your password, and you SHOULD ALWAYS secure it for whatever reason: sudo mkdir /root/.secrets sudo mv ~/certbot/cloudflare.ini /root/.secrets/. sudo chmod 700 /root/.secrets/ sudo chmod 400 /root/.secrets/cloudflare.ini OK, we will need to get the wildcard generated by running following: # Change example.com,*.example.com to your own domain name sudo certbot certonly --dns-cloudflare \\ -dns-cloudflare-credentials /root/.secrets/cloudflare.ini \\ -d example.com,*.example.com \\ --preferred-challenges dns-01 You can view your current certificates information by running: sudo certbot certificates Saving debug log to /var/log/letsencrypt/letsencrypt.log - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Found the following certs: Certificate Name: ryc.one Domains: ryc.one *.ryc.one Expiry Date: 2019-12-24 07:16:09+00:00 (VALID: 89 days) Certificate Path: /etc/letsencrypt/live/ryc.one/fullchain.pem Private Key Path: /etc/letsencrypt/live/ryc.one/privkey.pem - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - To renew your certificate by simply running sudo certbot renew, or a crontab job can be simply like: 14 5 * * * /usr/local/bin/certbot renew --quiet --post-hook \"/usr/sbin/service nginx reload\" \u003e /dev/null 2\u003e\u00261 Or if you want to renew your certificate to specific directory, you can have --config-dir, --work-dir, --logs-dir specified. If you are going to run this in a docker image which doesn‚Äôt have any file hosted, alway running as new, you may also consider add --agree-tos and -m EMAIL for script automation, full script is like below: certbot certonly --dns-cloudflare \\ --dns-cloudflare-credentials \\ /Users/riveryang/tmp/certsmgr/cloudflare.ini \\ -d 'ryc.one,*.ryc.one' \\ --preferred-challenges dns-01 \\ --config-dir /Users/riveryang/tmp/certsmgr \\ --work-dir /Users/riveryang/tmp/certsmgr \\ --logs-dir /Users/riveryang/tmp/certsmgr \\ --agree-tos -m river@ryc.one Well, it‚Äôs 90 days valid, with automatic renewal process, you can have it whenever you need it and wherever you need it. Happy operation~ R ","date":"2019-09-25","objectID":"/2019-09-25-get-you-a-free-ssl-cert/:0:0","tags":["SSL","Certificate"],"title":"Get You a Free SSL Cert","uri":"/2019-09-25-get-you-a-free-ssl-cert/"},{"categories":null,"content":"Error message showing as below while trying to login to on prem gitlab: gitlab access denied\u0026ldquo;gitlab access denied\u0026rdquo; \" gitlab access denied ","date":"2019-08-27","objectID":"/2019-08-27-gitlab-login-access-denied/:0:0","tags":["gitlab","access denied"],"title":"Gitlab Login Access Denied","uri":"/2019-08-27-gitlab-login-access-denied/"},{"categories":null,"content":"Background Gitlab is using LDAP (Microsoft Active Directory) to authenticate users. Confirmed with others users, only a small group of users are affected. Keep digging information by asking around‚Ä¶ previously, users were in 2 different ldap schema, admin used gitlab-rake gitlab:ldap:rename_provider[ldapbackup,ldapmain] to merge all old users to a single auth provider. But tested yesterday, login was fine. ","date":"2019-08-27","objectID":"/2019-08-27-gitlab-login-access-denied/:1:0","tags":["gitlab","access denied"],"title":"Gitlab Login Access Denied","uri":"/2019-08-27-gitlab-login-access-denied/"},{"categories":null,"content":"Diagnostic check log file: /var/log/gitlab/gitlab-rail/production.log while perform login action again‚Ä¶ tail -f /var/log/gitlab/gitlab-rail/production.log Find following in the log file: Processing by Ldap::OmniauthCallbacksController#ldapmain as HTML Parameters: {\"utf8\"=\u003e\"‚úì\", \"authenticity_token\"=\u003e\"[FILTERED]\", \"username\"=\u003e\"riveryang\", \"password\"=\u003e\"[FILTERED]\"} LDAP search error: No Such Object LDAP search error: No Such Object Could not update DN for riveryang (451) error messages: {:extern_uid=\u003e[\"has already been taken\"], :user=\u003e[\"has already been taken\"]} Redirected to https://gitlab.domain.works/users/sign_in Seems like it cannot find my name riveryang by using DN, but when trying to update with new DN, error saying extern_uid and user has been taken Searched around in Google, cannot find any useful information‚Ä¶ check in db (danger, please make sure you know what you are doing) I don‚Äôt know what‚Äôs gitlab‚Äôs DB looks like, so decided to look around. lol~ # Entering DB console gitlab-rails dbconsole # list current DB - psql cli command gitlabhq_production=\u003e \\l gitlabhq_production | gitlab | UTF8 | en_US.UTF-8 | en_US.UTF-8 | postgres | gitlab-psql | UTF8 | en_US.UTF-8 | en_US.UTF-8 | template0 | gitlab-psql | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/\"gitlab-psql\" + | | | | | \"gitlab-psql\"=CTc/\"gitlab-psql\" template1 | gitlab-psql | UTF8 | en_US.UTF-8 | en_US.UTF-8 | \"gitlab-psql\"=CTc/\"gitlab-psql\"+ | | | | | =c/\"gitlab-psql\" # switch databases gitlabhq_production=\u003e \\c gitlabhq_production psql (10.9, server 10.7) You are now connected to database \"gitlabhq_production\" as user \"gitlab\". # list all tables gitlabhq_production=\u003e \\dt public | abuse_reports | table | gitlab public | allowed_email_domains | table | gitlab public | analytics_cycle_analytics_group_stages | table | gitlab public | analytics_cycle_analytics_project_stages | table | gitlab public | appearances | table | gitlab public | application_setting_terms | table | gitlab public | application_settings | table | gitlab public | approval_merge_request_rule_sources | table | gitlab public | approval_merge_request_rules | table | gitlab .... There is one table users, have a look what‚Äôs inside: gitlabhq_production=\u003e select * from users; id | email | encrypted_password | reset_password_token | reset_password_sent_at | remember_created_at | sign_in_count | current_sign_in_at | last_sign_in_at | current_sign_in_ip | last_sign_in_ip | created_at | updated_at | name | admin | projects_limit | skype | linkedin | twitter | bio | failed_attempts | locked_at | username | can_create_group | can_create_team | state | color_scheme_id | password_expires_at | created_by_id | last_credential_check_at | avatar | confirmation_token | confirmed_at | confirmation_sent_at | unconfirmed_email | hide_no_ssh_key | website_url | admin_email_unsubscribed_at | notification_email | hide_no_password | password_automatically_set | location | encrypted_otp_secret | encrypted_otp_secret_iv | encrypted_otp_secret_salt | otp_required_for_login | otp_backup_codes | public_email | dashboard | project_view | consumed_timestep | layout | hide_project_limit | note | unlock_token | otp_grace_period_started_at | external | incoming_email_token | organization | auditor | require_two_factor_authentication_from_group | two_factor_grace_period | ghost | last_activity_on | notified_of_own_activity | preferred_language | email_opted_in | email_opted_in_ip | email_opted_in_source_id | email_opted_in_at | theme_id | accepted_term_id | feed_token | private_profile | roadmap_layout | include_private_contributions | commit_email | group_view | managing_group_id | bot_type ------+-------------------------------------------------+--------------------------------------------------------------+----------------------+------------------------+----------------------------+---------------+----------------------------+----------------------------+--------------------+-----------------+----------------------------+------------------","date":"2019-08-27","objectID":"/2019-08-27-gitlab-login-access-denied/:2:0","tags":["gitlab","access denied"],"title":"Gitlab Login Access Denied","uri":"/2019-08-27-gitlab-login-access-denied/"},{"categories":null,"content":"Let‚Äôs take a look at the following code: package main import ( \"fmt\" \"time\" ) func main() { timeString := time.Now().Format(\"2006-01-02 15:04:05\") fmt.Println(timeString) fmt.Println(time.Now().Format(\"2019-08-20 18:05:32\")) } Here is some ref for golang‚Äôs time format: https://yourbasic.org/golang/format-parse-string-time-date-example/ Any idea what‚Äôs the result before actually running it? What? You know the trick? Oh, man, don‚Äôt waste your time here, skip this one and go have a beer üç∫ ","date":"2019-08-20","objectID":"/2019-08-20-magic-date-in-golang-2006-01-02-150405/:0:0","tags":["golang","2006-01-02 15:04:05","2006-01-02"],"title":"Magic Date in Golang: 2006-01-02 15:04:05","uri":"/2019-08-20-magic-date-in-golang-2006-01-02-150405/"},{"categories":null,"content":"The magic date As the reference showing above, I was thinking ‚Äúuhmm, so we can just imagine and give an example about the date what it should look like, then golang will help us to format it properly? that‚Äôs awesome!‚Äù But when come acroos in the real scenario‚Ä¶ // result -\u003e 2019-08-23 23:06:54 23089-08-230 88:54:1123 What‚Äôs the‚Ä¶ 23089-08-230‚Ä¶ ??? ","date":"2019-08-20","objectID":"/2019-08-20-magic-date-in-golang-2006-01-02-150405/:1:0","tags":["golang","2006-01-02 15:04:05","2006-01-02"],"title":"Magic Date in Golang: 2006-01-02 15:04:05","uri":"/2019-08-20-magic-date-in-golang-2006-01-02-150405/"},{"categories":null,"content":"Investigation After bit research, it turns out that‚Äôs actually a ‚Äúfixed‚Äù value that should be exactly showing there as ‚Äú2006-01-02‚Äù, it cannot be anything else. ref: https://gobyexample.com/time-formatting-parsing ref: https://programming.guide/go/format-parse-string-time-date-example.html But why??? ","date":"2019-08-20","objectID":"/2019-08-20-magic-date-in-golang-2006-01-02-150405/:2:0","tags":["golang","2006-01-02 15:04:05","2006-01-02"],"title":"Magic Date in Golang: 2006-01-02 15:04:05","uri":"/2019-08-20-magic-date-in-golang-2006-01-02-150405/"},{"categories":null,"content":"More research‚Ä¶ Well, nothing is more clearly than the source code itself‚Ä¶ ref: https://github.com/golang/go/blob/master/src/time/format.go const ( _ = iota stdLongMonth = iota + stdNeedDate // \"January\" stdMonth // \"Jan\" stdNumMonth // \"1\" stdZeroMonth // \"01\" stdLongWeekDay // \"Monday\" stdWeekDay // \"Mon\" stdDay // \"2\" stdUnderDay // \"_2\" stdZeroDay // \"02\" stdUnderYearDay // \"__2\" stdZeroYearDay // \"002\" stdHour = iota + stdNeedClock // \"15\" stdHour12 // \"3\" stdZeroHour12 // \"03\" stdMinute // \"4\" stdZeroMinute // \"04\" stdSecond // \"5\" stdZeroSecond // \"05\" stdLongYear = iota + stdNeedDate // \"2006\" stdYear // \"06\" stdPM = iota + stdNeedClock // \"PM\" stdpm // \"pm\" stdTZ = iota // \"MST\" stdISO8601TZ // \"Z0700\" // prints Z for UTC stdISO8601SecondsTZ // \"Z070000\" stdISO8601ShortTZ // \"Z07\" stdISO8601ColonTZ // \"Z07:00\" // prints Z for UTC stdISO8601ColonSecondsTZ // \"Z07:00:00\" stdNumTZ // \"-0700\" // always numeric stdNumSecondsTz // \"-070000\" stdNumShortTZ // \"-07\" // always numeric stdNumColonTZ // \"-07:00\" // always numeric stdNumColonSecondsTZ // \"-07:00:00\" stdFracSecond0 // \".0\", \".00\", ... , trailing zeros included stdFracSecond9 // \".9\", \".99\", ..., trailing zeros omitted stdNeedDate = 1 \u003c\u003c 8 // need month, day, year stdNeedClock = 2 \u003c\u003c 8 // need hour, minute, second stdArgShift = 16 // extra argument in high bits, above low stdArgShift stdMask = 1\u003c\u003cstdArgShift - 1 // mask out argument ) So it covers everything for the time format‚Ä¶ How it calculates the time, it shows here: ref: https://github.com/golang/go/blob/master/src/time/format.go in func ‚ÄúnextStdChunk‚Äù func nextStdChunk(layout string) (prefix string, std int, suffix string) { for i := 0; i \u003c len(layout); i++ { switch c := int(layout[i]); c { case 'J': // January, Jan if len(layout) \u003e= i+3 \u0026\u0026 layout[i:i+3] == \"Jan\" { if len(layout) \u003e= i+7 \u0026\u0026 layout[i:i+7] == \"January\" { return layout[0:i], stdLongMonth, layout[i+7:] } if !startsWithLowerCase(layout[i+3:]) { return layout[0:i], stdMonth, layout[i+3:] } } case 'M': // Monday, Mon, MST if len(layout) \u003e= i+3 { if layout[i:i+3] == \"Mon\" { if len(layout) \u003e= i+6 \u0026\u0026 layout[i:i+6] == \"Monday\" { return layout[0:i], stdLongWeekDay, layout[i+6:] } if !startsWithLowerCase(layout[i+3:]) { return layout[0:i], stdWeekDay, layout[i+3:] } } if layout[i:i+3] == \"MST\" { return layout[0:i], stdTZ, layout[i+3:] } } case '0': // 01, 02, 03, 04, 05, 06, 002 if len(layout) \u003e= i+2 \u0026\u0026 '1' \u003c= layout[i+1] \u0026\u0026 layout[i+1] \u003c= '6' { return layout[0:i], std0x[layout[i+1]-'1'], layout[i+2:] } if len(layout) \u003e= i+3 \u0026\u0026 layout[i+1] == '0' \u0026\u0026 layout[i+2] == '2' { return layout[0:i], stdZeroYearDay, layout[i+3:] } case '1': // 15, 1 if len(layout) \u003e= i+2 \u0026\u0026 layout[i+1] == '5' { return layout[0:i], stdHour, layout[i+2:] } return layout[0:i], stdNumMonth, layout[i+1:] case '2': // 2006, 2 if len(layout) \u003e= i+4 \u0026\u0026 layout[i:i+4] == \"2006\" { return layout[0:i], stdLongYear, layout[i+4:] } return layout[0:i], stdDay, layout[i+1:] case '_': // _2, _2006, __2 if len(layout) \u003e= i+2 \u0026\u0026 layout[i+1] == '2' { //_2006 is really a literal _, followed by stdLongYear if len(layout) \u003e= i+5 \u0026\u0026 layout[i+1:i+5] == \"2006\" { return layout[0 : i+1], stdLongYear, layout[i+5:] } return layout[0:i], stdUnderDay, layout[i+2:] } if len(layout) \u003e= i+3 \u0026\u0026 layout[i+1] == '_' \u0026\u0026 layout[i+2] == '2' { return layout[0:i], stdUnderYearDay, layout[i+3:] } case '3': return layout[0:i], stdHour12, layout[i+1:] case '4': return layout[0:i], stdMinute, layout[i+1:] case '5': return layout[0:i], stdSecond, layout[i+1:] case 'P': // PM if len(layout) \u003e= i+2 \u0026\u0026 layout[i+1] == 'M' { return layout[0:i], stdPM, layout[i+2:] } case 'p': // pm if len(layout) \u003e= i+2 \u0026\u0026 layout[i+1] == 'm' { return layout[0:i], stdpm, layout[i+2:] } case '-': // -070000, -07:00:00, -0700, -07:00, -07 if len(layout) \u003e= i+7 \u0026\u0026 layout[i:i+7] == \"-070000\" { return layout[0:i], stdNumSecondsTz, layout[i+7:] } if len(layout) \u003e= i+9 \u0026\u0026 layout[i:i+9] == \"-07:00:00\" { return layout[0:i], stdNumColonSecondsTZ, layout[i+9:] } if le","date":"2019-08-20","objectID":"/2019-08-20-magic-date-in-golang-2006-01-02-150405/:3:0","tags":["golang","2006-01-02 15:04:05","2006-01-02"],"title":"Magic Date in Golang: 2006-01-02 15:04:05","uri":"/2019-08-20-magic-date-in-golang-2006-01-02-150405/"},{"categories":null,"content":"Chase is only 20 months old, but he eats a lot‚Ä¶ Well, he got a fat father, who can I blame‚Ä¶ - -||| Baby formula is always a hard thing to get in Australia as the producer is not able to supply enough to all Asian countries‚Ä¶ (No blame here‚Ä¶) Not many ways that we can get the formula: Chinese Daigou shop $37 per can, average $7 more than retail price Supermarket (Coles, WWS, etc‚Ä¶) Always out of stock Online (Mum‚Äôs store) 1 can per order with $10 postage fee = $30 + $10 even more expensive than Daigou shop So do it in golang with basic operations‚Ä¶ Find API for checking the stock level Call API to get result Sort JSON data Operate with data Find API Web page: https://www.woolworths.com.au/shop/productdetails/7211/aptamil-profutura-toddler-formula-stage-3 By clicking the Check stock in our stores to find out if it‚Äôs purchasable. With Chrome Dev Tool, the API url can be found out here: https://www.woolworths.com.au/apis/ui/product/7211/Stores?IncludeInStockStoreOnly=false\u0026Latitude=-33.7038507\u0026Longitude=151.1087877\u0026Max=5 In url 7211: product id IncludeInStockStoreOnly: limited result Latitude \u0026 Longitude: Location Max: limited result Call API Call API with golang by using http.Get: package main import ( \"fmt\" \"io/ioutil\" \"net/http\" ) func main() { // get stock status for item 7211 around Hornsby area from API call: https://www.woolworths.com.au/apis/ui/product/7211/Stores?IncludeInStockStoreOnly=false\u0026Latitude=-33.7038507\u0026Longitude=151.1087877\u0026Max=10 // Latitude \u0026 Longitude = Hornsby // 7211 = Atapmil pro-futura Toddler Formula Stage 3 900g // Max = maximum number of stores information as return resp, err := http.Get(\"https://www.woolworths.com.au/apis/ui/product/7211/Stores?IncludeInStockStoreOnly=false\u0026Latitude=-33.7038507\u0026Longitude=151.1087877\u0026Max=10\") if err != nil { panic(err) } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) fmt.Println(string(body)) } Result: [ { \"Store\":{ \"Division\":\"SUPERMARKETS\", \"StoreNo\":\"1294\", \"Name\":\"Hornsby\", \"AddressLine1\":\"Westfield Shopping Centre, 236 Pacific Highway\", \"AddressLine2\":null, \"Suburb\":\"Hornsby\", \"State\":\"NSW\", \"Postcode\":\"2077\", \"Latitude\":\"-33.704725\", \"Longitude\":\"151.099336\", \"GeoLevel\":\"0\", \"Distance\":\"0.9\", \"Phone\":\"(02) 9450 6712\", \"TradingHours\":[ { \"Day\":\"Today\", \"OpenHour\":\"6:00 AM - 10:00 PM\", \"TradingHourForDisplay\":\"Mon: 0600-2200\" }, { \"Day\":\"Tomorrow\", \"OpenHour\":\"6:00 AM - 10:00 PM\", \"TradingHourForDisplay\":\"Tue: 0600-2200\" }, { \"Day\":\"Wednesday\", \"OpenHour\":\"6:00 AM - 10:00 PM\", \"TradingHourForDisplay\":\"Wed: 0600-2200\" }, { \"Day\":\"Thursday\", \"OpenHour\":\"6:00 AM - 10:00 PM\", \"TradingHourForDisplay\":\"Thu: 0600-2200\" }, { \"Day\":\"Friday\", \"OpenHour\":\"6:00 AM - 10:00 PM\", \"TradingHourForDisplay\":\"Fri: 0600-2200\" }, { \"Day\":\"Saturday\", \"OpenHour\":\"6:00 AM - 10:00 PM\", \"TradingHourForDisplay\":\"Sat: 0600-2200\" }, { \"Day\":\"Sunday\", \"OpenHour\":\"6:00 AM - 10:00 PM\", \"TradingHourForDisplay\":\"Sun: 0600-2200\" }, { \"Day\":\"Monday\", \"OpenHour\":\"6:00 AM - 10:00 PM\", \"TradingHourForDisplay\":\"Mon: 0600-2200\" } ], \"Facilities\":[ \"Coffee Shop\", \"Seafood\", \"Sushi Bar\", \"Pick up\", \"eBay Online Order Collection\", \"EziBuy Online Order Collection\", \"Click and Collect\" ] }, \"ListPrice\":0, \"InstoreListPrice\":0, \"SalePrice\":0, \"InstoreSalePrice\":0, \"CUPListPrice\":0, \"InstoreCUPListPrice\":0, \"CUPSalePrice\":0, \"InstoreCUPSalePrice\":0, \"HideWasSavedPrice\":false, \"IsRanged\":true, \"IsInStock\":false, \"IsForCollection\":false, \"IsForDelivery\":false, \"IsForExpress\":false, \"IsSpecial\":false, \"IsAvailable\":false, \"InstoreIsAvailable\":false, \"IsPurchasable\":false, \"InstoreIsPurchasable\":false, \"IsOnSpecial\":false, \"InstoreIsOnSpecial\":false, \"IsNew\":false } ] Analysis Data To analysis JSON data, we need to declare the data structure based on JSON result first: type product_store_level []struct { Store struct { Division string `json:\"Division\"` StoreNo string `json:\"StoreNo\"` Name string `json:\"Name\"` AddressLine1 string `json:\"AddressLine1\"` AddressLine2 interface{} `json:\"AddressLine2\"` Suburb","date":"2019-08-19","objectID":"/2019-08-18-daddy-where-is-my-formula/:0:0","tags":["golang","api"],"title":"Daddy, where is my formula?","uri":"/2019-08-18-daddy-where-is-my-formula/"},{"categories":null,"content":"Well, it‚Äôs been a long time that not posting things‚Ä¶ and I know the excuse is very easy to find‚Ä¶ So I have to admit I was lazy‚Ä¶ Got a new Macbook from Apple (after repair), same as usual, install brew, then bulk install all applications I need‚Ä¶ Uhm, wait, my iterm2 is not working as I expected‚Ä¶ all shortcuts are not working at all! The last time I configured the shortcuts was looooong time ago, and I forgot to record down everything‚Ä¶ OK, learnt this time so I decided to put something here to remind myselft‚Ä¶ Open the iTerm preferences ‚åò+, and navigate to the Profiles tab (the Keys tab can be used, but adding keybinding to your profile allows you to save your profile and sync it to multiple computers) and keys sub-tab and enter the following: Delete all characters left of the cursor ‚åò+‚ÜêDelete Send Hex Codes: 0x18 0x7f ‚Äì Less compatible, doesn‚Äôt work in node and won‚Äôt work in zsh by default, see below to fix zsh (bash/irb/pry should be fine), performs desired functionality when it does work. 0x15 ‚Äì More compatible, but typical functionality is to delete the entire line rather than just the characters to the left of the cursor. Delete all characters right of the cursor ‚åò+fn+‚ÜêDelete or ‚åò+Delete‚Üí Send Hex Codes: 0x0b Delete one word to left of cursor ‚å•+‚ÜêDelete Send Hex Codes: 0x01b 0x08 Delete one word to right of cursor ‚å•+fn‚ÜêDelete or ‚å•+Delete‚Üí Send Hex Codes: 0x01b 0x64 Move cursor to the front of line ‚åò+‚Üê Send Hex Codes: 0x01 Move cursor to the end of line ‚åò+‚Üí Send Hex Codes: 0x05 Move cursor one word left ‚å•+‚Üê Send Hex Codes: 0x1b 0x62 Move cursor one word right ‚å•+‚Üí Send Hex Codes: 0x1b 0x66 Undo ‚åò+z Send Hex Codes: 0x1f Redo Typically not bound in bash, zsh or readline, so we can set it to a unused hexcode which we can then fix in zsh. ‚áß+‚åò+Z or ‚åò+y Send Hex Codes: 0x18 0x1f _Stolen from: http://stackoverflow.com/questions/6205157/iterm2-how-to-get-jump-to-beginning-end-of-line-in-bash-shell#answer-29403520_ Make sure you backup your own profile well‚Ä¶ ","date":"2019-07-28","objectID":"/2019-07-28-iterm2-in-mac/:0:0","tags":["Iterm2","MAC"],"title":"Iterm2 in MAC","uri":"/2019-07-28-iterm2-in-mac/"},{"categories":null,"content":"I‚Äôm currently in China with GFW (google it~), so I‚Äôm fully ‚Äúprotected‚Äù by Chinese Goverment \u003c- Thanks very much! But I still need Google to do something really bad, or for all my Aussie friends, you may need it for US Netflix‚Ä¶ :) This is the list about what you will need to prepare: US VPS (Virtual Private Server): e.g. Azure, AWS or other cloud service provider (whichever stable and cheap) A Linux image (I‚Äôm using Centos, but others are fine as we only use Docker) Docker Image: SSR client Windows: Download Here MAC: To be finished Router: ASUS AC86U (recommand) To be finished I‚Äôll assume that you have already ssh into the server you created in US. Install Docker as root yum install docker -y Enable service systemctl enable docker systemctl start docker Pull docker image docker pull riveryc/ssr:latest Or build your own by using this Dockerfile # shadowsocks # # VERSION 0.0.3 FROM python:3.7-alpine3.7 MAINTAINER River Yang \u003criver@ryc.one\u003e # RUN apt-get update \u0026\u0026 \\ # apt-get install -y python-pip libsodium18 RUN pip install shadowsocks==2.8.2 # Configure container to run as an executable ENTRYPOINT [\"/usr/local/bin/ssserver\"] Run the image with your own config # Server side will run image \"riveryc/ssr:latest\" on port 12355 to serve all requests from anywhere (0.0.0.0) with the password $SSPASSWORD in environment variable which has been declared earlier as \"your_own_password\". All above port \u0026 password can be changed to whatever you want. # -m is the encryption methods, just use this one... export SSPASSWORD=your_own_password docker run -d -p 12355:12355 riveryc/ssr:latest -s 0.0.0.0 -p 12355 -k $SSPASSWORD -m aes-256-cfb Configure your firewall rule in cloud to enable the port for your VPS to public via External IP: Do this in web console‚Ä¶ Allow your port is accessible. Configure your local client (Windows): mine is in Japan as it‚Äôs the fastest node for me right now, you can put your US IP. Configure your local client (MAC) Configure your local client (Router) Check your current IP here Enable your client (Windows) Check your IP again now Will update MAC Client tomorrow‚Ä¶ Router‚Ä¶ will be the last one as it needs more changes‚Ä¶ and I‚Äôm 100% sure you will LOSE your warranty for your $200 device, so double think before doing it. ","date":"2019-02-25","objectID":"/2019-02-25-go-to-another-country-via-ssr/:0:0","tags":["VPN","SSR"],"title":"Go to Another Country via SSR","uri":"/2019-02-25-go-to-another-country-via-ssr/"},{"categories":null,"content":"I‚Äôd assume ADFS has already been setup correctly. We‚Äôll only concentrate on How to setup ADFS side and AWS side for SSO with SAML ","date":"2018-12-17","objectID":"/2018-12-17-aws-sso-with-adfs-part-2/:0:0","tags":["aws","adfs","sso"],"title":"AWS SSO With ADFS - Part 2","uri":"/2018-12-17-aws-sso-with-adfs-part-2/"},{"categories":null,"content":"Design \u0026 Implementation ","date":"2018-12-17","objectID":"/2018-12-17-aws-sso-with-adfs-part-2/:1:0","tags":["aws","adfs","sso"],"title":"AWS SSO With ADFS - Part 2","uri":"/2018-12-17-aws-sso-with-adfs-part-2/"},{"categories":null,"content":"AWS Side We will be using Identity providers - SAML type - with Provider name as -\u003e ADFS Metadata Document can be granted from URL: https://\u003cyour_adfs_url\u003e/FederationMetadata/2007-06/FederationMetadata.xml We need to create Role for all kind-like users in the same AD group to be mapped in AWS. Let‚Äôs create a role called \u003caccountName\u003e-admin, like sandbox-admin, and binds with ‚ÄúAdministrators‚Äù permission with it. Select SAML 2.0 federation Select ADFS previously created as the provider Select the way you want users to access the console or resources, here I select Allow programmatic and AWS Management Console access Next, permission, we tick Administrators Next, Next, Role name: sandbox-admin Till here, all AWS side is finished. ","date":"2018-12-17","objectID":"/2018-12-17-aws-sso-with-adfs-part-2/:1:1","tags":["aws","adfs","sso"],"title":"AWS SSO With ADFS - Part 2","uri":"/2018-12-17-aws-sso-with-adfs-part-2/"},{"categories":null,"content":"On-prem AD side The main steps are pretty much the same as: https://aws.amazon.com/blogs/security/aws-federated-authentication-with-active-directory-federation-services-ad-fs/ However, I made some changes to adopt with more features: As users will be granting permissions by joining to an AD group, so we will need to create a group before doing anything: AWSGlobal-123456789012-sandbox-admin AWSGlobal: hard-coded value as prefix showing what is this for. \u003c- by having this one, you will be able to map to different region, like China or Gov 123456789012: AWS Account ID in number. \u003c- by changing this bit, you will be able to map to different accounts. sandbox-admin: role name (created in AWS side). \u003c- by changing this, you will be able to login to different role with different permission. In ADFS configuration, Role Attributes should be following: c:[Type== \"http://temp/variable\", Value =~ \"(?i)^AWSGlobal-([\\d]{12})-([a-zA-Z]*)-\"] =\u003e issue(Type = \"https://aws.amazon.com/SAML/Attributes/Role\", Value = RegExReplace(c.Value, \"AWSGlobal-([\\d]{12})-\", \"arn:aws:iam::$1:saml-provider/ADFS,arn:aws:iam::$1:role/\")); Leave the rest the same as above link. Then try to login from ADFS portal, you will be redirect to AWS Console with correct permission as sandbox-admin. Have fun there. R ","date":"2018-12-17","objectID":"/2018-12-17-aws-sso-with-adfs-part-2/:1:2","tags":["aws","adfs","sso"],"title":"AWS SSO With ADFS - Part 2","uri":"/2018-12-17-aws-sso-with-adfs-part-2/"},{"categories":null,"content":"I‚Äôm a lazy man, so always thinking to integrate things together to reduce anything to remember. AWS provides its own way to authenticate users via IAM module, however it‚Äôs just another system to me, so as another credential to me to manage‚Ä¶ I guess any IT won‚Äôt like it as too many places to create/delete/disable users, so does user‚Ä¶ I think pretty much security will join the party too. AWS provides another way to authenticate user via Role. What we need to do, is relaying on the SAML provider to authenticate our users in AD via ADFS portal, then map all users to the specific role in AWS account: Finance: Mark John Susan Operation: Jay Peter Tom In AWS, we can create 2 roles for above groups: finance operation Thus, as long as user are in the specified AD group, they are able to login to AWS with certain permission without remembering another credential. How it works: User accesses to ADFS web portal User‚Äôs credential is passed to Windows AD to get authenticated Get the authentication response (SAML assertion) from AD and send back to user‚Äôs end User use this authentication response (SAML assertion) to post to AWS endpoint. AWS side will use AssumeRoleWithSAML with the ‚ÄúSAML assertion‚Äù to authorise user to the role specified. AWS will return the Management Console back to user as the role specified. Part 2 will introduce the strategy and how to set it up ","date":"2018-12-16","objectID":"/2018-12-16-aws-sso-with-adfs-part-1/:0:0","tags":["aws","adfs","sso"],"title":"AWS SSO With ADFS - Part 1","uri":"/2018-12-16-aws-sso-with-adfs-part-1/"},{"categories":null,"content":"Sometime it‚Äôs just hard (lazy) to find an existing module (package in Go) for certain work‚Ä¶ For something small or handy, we may just run a bash command from the app‚Ä¶ For this one, I‚Äôll only cover the run basic bash command from Go as later on I‚Äôll do struct (class in Go) to cover bit more for iptables. Running bash command in Go it‚Äôs simple, we need following vars to be prepared: cmd: command string args: arguments string array import ‚Äúos‚Äù and ‚Äúos/exec‚Äù packages (this is normally done by IDE) And we are good to go~ create a new HandleFunc in main function called ‚Äúexec‚Äù, then assign a new function for this handler ‚Äúexeccmd‚Äù: http.HandleFunc(\"/exec\",execcmd) This will make sure that when I access ‚Äúhttp://localhost:8080/exec‚Äù, function execcmd will be executed. Add new function execcmd: func execcmd(w http.ResponseWriter, r *http.Request) { cmd := \"ls\" args := []string{\"-al\"} cmdout, err := exec.Command(cmd,args...).Output() if err != nil { fmt.Fprint(w, err) } out := string(cmdout) fmt.Fprintln(w,out) } I just used the very simple bash command here as example ‚Äúls -al‚Äù. Line 8 is necessary as var ‚Äúcmdout‚Äù by default type is byte[], so we have to convert it to string, so that it can be read from the console and showing on the site. Here is the result by accessing that URL: total 8 drwxr-xr-x 4 ryang 1825648216 136 Oct 16 07:23 . drwxr-xr-x 7 ryang 1825648216 238 Oct 13 20:38 .. drwxr-xr-x 7 ryang 1825648216 238 Oct 16 07:23 .idea -rw-r--r-- 1 ryang 1825648216 1199 Oct 16 07:23 webapp.go Shows existing folder‚Äôs folder and files‚Ä¶ R ","date":"2018-10-15","objectID":"/2018-10-15-go-day-3/:0:0","tags":["golang"],"title":"Go Day 3","uri":"/2018-10-15-go-day-3/"},{"categories":null,"content":"While you have multiple pages (or functions)‚Ä¶ In my case, I‚Äôll have basic following pages: Index: list all iptable rules (Get) Inbound: list all inbound nat rules (Get) Outbound: list all outbound nat rules (Get) Yesterday, I‚Äôve used ‚Äúhttp.HandleFunc()‚Äù to send json as index, so I‚Äôll do the same for in/outbound list, and write them into different functions, call functions from the main script: Nothing fancy, nothing new, just code here: package main import ( \"encoding/json\" \"net/http\" ) func index(w http.ResponseWriter, r *http.Request) { mapindex := map[string]interface{}{\"tittle\": \"iptables\", \"region_name\": \"region_name\", \"region_number\": 52, \"iptables\":\"172.26.52.11\"} json.NewEncoder(w).Encode(mapindex) } func inbound(w http.ResponseWriter, r *http.Request) { mapinbound := map[string]interface{}{\"tittle\":\"inbound\", \"region_name\": \"region_name\", \"region_number\": 52, \"inbound rules\": \"inbound\"} json.NewEncoder(w).Encode(mapinbound) } func outbound(w http.ResponseWriter, r *http.Request) { mapinbound := map[string]interface{}{\"tittle\":\"inbound\", \"region_name\": \"region_name\", \"region_number\": 52, \"inbound rules\": \"outbound\"} json.NewEncoder(w).Encode(mapinbound) } func main() { http.HandleFunc(\"/\", index) http.HandleFunc(\"/inbound\", inbound) http.HandleFunc(\"/outbound\", outbound) http.ListenAndServe(\":8080\", nil) } Will do bash run tomorrow‚Ä¶ R ","date":"2018-10-14","objectID":"/2018-10-14-go-day-2/:0:0","tags":["golang"],"title":"Go Day 2","uri":"/2018-10-14-go-day-2/"},{"categories":null,"content":"Should I start with ‚ÄúHello World‚Äù? Or we should get started with Installation? I‚Äôll go direct to something I want‚Ä¶ :) I want to build a webapp: A website is listening on port 8080 (can be any) Get current iptables information from localhost (Ubuntu) Output to frontend with JSON data Have inbound and outbound rule: GET and POST So following points will be covered: Create a basic website instead of outputing ‚ÄúHello world‚Äù, output JSON data Go: deal with different route as different functions in this WebApp Go: Run bash in golang Go: Get stdout from running bash Go: Create class (struct) in golang Go: Embedded types in golang Go: Create method in golang Go: Create interface in golang Go: String build in golang I‚Äôll see how long it will take me to cover all above‚Ä¶ probably will be a while‚Ä¶ Day 1: package main import ( \"encoding/json\" \"net/http\" ) func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { mapD := map[string]string{\"Name\": \"River\", \"Hello\": \"World\"} json.NewEncoder(w).Encode(mapD) }) http.ListenAndServe(\":8080\", nil) } Need to go‚Ä¶ but simple code to get started, always good. ;) R ","date":"2018-10-13","objectID":"/2018-10-13-go-day-1/:0:0","tags":["golang"],"title":"Go Day 1","uri":"/2018-10-13-go-day-1/"},{"categories":null,"content":"I was trying to run ‚Äòdocker-compose‚Äô in our environment today, but found following message from RedHat officially: So we are on our own‚Ä¶ Get the latest version from Github: [https://github.com/docker/compose/releases] Same as usual, link it to /usr/local/bin/docker-compose Give it exe permission‚Ä¶ However, here is the problem happening in RHEL 7.4: docker-compose: error while loading shared libraries: libz.so.1: failed to map segment from shared object: Operation not permitted I tried to disable SElinux, not working‚Ä¶ Finally, I came across this github issue and I tried one of the workarounds which worked in my instance. Solution was to remount tmp with exec permission by executing : sudo mount /tmp -o remount,exec Or have following ansible block: - name:makemounttmpwithexecmount:path:\"/tmp\"state:mountedsrc:/dev/mapper/rootvg-tmpvol# your own real pathfstype:xfs# your own real typeopts:nodev,nosuid# as long as you don't have noexec... :) Problem resolved. Happy docker-compose~ River ","date":"2018-04-04","objectID":"/2018-04-04-run-docker-compose-in-rhel/:0:0","tags":["Docker","Redhat"],"title":"Run docker-compose in RHEL","uri":"/2018-04-04-run-docker-compose-in-rhel/"},{"categories":null,"content":"When you have UAC enabled, most of the time, the default PowerShell ISE is opened with normal process. This is not going to work when you want to apply the DSC resources. Have to have an administrative PowerShell process running to get it done. However, my own account doesn‚Äôt have certain permission to access an encrypted vault. Thus I have to run as another account. Here is what we should do‚Ä¶ Open up PowerShell Console as administrator by right clicking the icon, and select ‚ÄúRun as Administrator‚Äù. Then put in following: (assume the user you are going use is Domain user ‚Äúdomain\\superuser‚Äù) Start-Process powershell.exe -Credential ‚ÄúDomain\\SuperUser‚Äù -ArgumentList ‚ÄúStart-Process powershell_ise.exe -Verb runAs‚Äù The new PowerShell ISE with ‚ÄúDomain\\SuperUser‚Äù credential \u0026 Administrator permission is open. :) Enjoy‚Ä¶ ","date":"2018-03-15","objectID":"/2018-03-15-powershell-run-as-another-user-elevate-the-process/:0:0","tags":["PowerShell","Windows"],"title":"PowerShell Run as Another User \u0026 Elevate the Process","uri":"/2018-03-15-powershell-run-as-another-user-elevate-the-process/"},{"categories":null,"content":"The SAML authentication for Chrome in OS X is not supported as well as it‚Äôs running in Windows. Here is what we need to do: #!/bin/sh loggedInUser=`python -c 'from SystemConfiguration import SCDynamicStoreCopyConsoleUser; import sys; username = (SCDynamicStoreCopyConsoleUser(None, None, None) or [None])[0]; username = [username,\"\"][username in [u\"loginwindow\", None, u\"\"]]; sys.stdout.write(username + \"\\n\");'` echo $loggedInUser sudo -u $loggedInUser defaults write com.google.Chrome AuthServerWhitelist \"Your SAML URL\" sudo -u $loggedInUser defaults write com.google.Chrome AuthNegotiateDelegateWhitelist \"Your SAML URL\" echo $(date) exit 0 There you go, restart your Chrome, and enjoy. :) ","date":"2017-12-28","objectID":"/2017-12-28-saml-authentication-for-chrome-in-mac-os/:0:0","tags":["tagA","tagB"],"title":"SAML Authentication for Chrome in OSX","uri":"/2017-12-28-saml-authentication-for-chrome-in-mac-os/"},{"categories":null,"content":"Tried different ways to enable the Remote API, never get any luck on anything‚Ä¶ But finally, here is what I did, that works! vi /etc/sysconfig/docker Here is my docker content: #/etc/sysconfig/docker # Modify these options if you want to change the way the docker daemon runs OPTIONS='--selinux-enabled --log-driver=journald --signature-verification=false' if [ -z \"${DOCKER_CERT_PATH}\" ]; then DOCKER_CERT_PATH=/etc/docker fi # Do not add registries in this file anymore. Use /etc/containers/registries.conf # from the atomic-registries package. # # docker-latest daemon can be used by starting the docker-latest unitfile. # To use docker-latest client, uncomment below lines #DOCKERBINARY=/usr/bin/docker-latest #DOCKERDBINARY=/usr/bin/dockerd-latest #DOCKER_CONTAINERD_BINARY=/usr/bin/docker-containerd-latest #DOCKER_CONTAINERD_SHIM_BINARY=/usr/bin/docker-containerd-shim-latest Add '-H tcp://127.0.0.1:4243 -H unix:///var/run/docker.sock' in the 'OPTIONS': OPTIONS='--selinux-enabled --log-driver=journald --signature-verification=false -H tcp://127.0.0.1:4243 -H unix:///var/run/docker.sock' Then restart your docker daemon by systemctl restart docker Test: curl 127.0.0.1:4243/version {\"Version\":\"1.12.6\",\"ApiVersion\":\"1.24\",\"GitCommit\":\"0fdc778/1.12.6\",\"GoVersion\":\"go1.8.3\",\"Os\":\"linux\",\"Arch\":\"amd64\",\"KernelVersion\":\"3.10.0-327.10.1.el7.x86_64\",\"BuildTime\":\"2017-07-20T00:06:39.987144400-04:00\",\"PkgVersion\":\"docker-1.12.6-48.git0fdc778.el7.x86_64\"} Done~ This only enables the local port, so it‚Äôs secure for testing purpose. ","date":"2017-09-06","objectID":"/2017-09-06-enable-docker-remote-api-in-redhat-centos-7/:0:0","tags":["Docker","CentOS","Redhat"],"title":"Enable Docker Remote API in Redhat/CentOS 7","uri":"/2017-09-06-enable-docker-remote-api-in-redhat-centos-7/"},{"categories":null,"content":"I‚Äôm very noob .Net C# developer, but I remember this: \u003ccompare\u003e ? \u003cvalue of true\u003e : \u003cvalue of false\u003e (a == ‚Äòa‚Äô ) ? 1 : 2 I want the same thing in PowerShell, here we go: . ({'condition is false'},{'condition is true'})[$condition] Sample: @(\"false\",\"true\")[\"a\" -eq \"b\"] Which I came up with a more readable and something easy to memory: @{$true=1;$false=2}[$a -eq 'a'] Happy scripting‚Ä¶. ","date":"2017-07-15","objectID":"/2017-07-15-ternary-operator-in-powershell/:0:0","tags":["PowerShell"],"title":"Ternary Operator in PowerShell","uri":"/2017-07-15-ternary-operator-in-powershell/"},{"categories":null,"content":"You may have some arrays like this: $year1 = @() $year1 += \"Cindy\" $year1 += \"Candy\" $year1 += \"Mandy\" $year2 = @() $year2 += \"Chris\" $year2 += \"Green\" $year2 += \"Richard\" Then you may want to combine them together: $School = @() $School += $year1 $School += $year2 But unfortunately it‚Äôs not simple like this‚Ä¶ You will get: PS C:\\River\u003e $School.Count 6 Suppose to be 2, right? Why it‚Äôs 6‚Ä¶ Let‚Äôs identify‚Ä¶ PS C:\\River\u003e foreach ($item in $School){ Write-Host \"Item index: $($School.IndexOf($item)), Item value: $($item)\" } Item index: 0, Item value: Cindy Item index: 1, Item value: Candy Item index: 2, Item value: Mandy Item index: 3, Item value: Chris Item index: 4, Item value: Green Item index: 5, Item value: Richard But what I want it to be is $School contains $year1 and $year2, and $year1 contains its own people, the same as $year2. Here is the solution‚Ä¶ $School = @() $School += ,$year1 $School += ,$year2 Let‚Äôs double check the new array: PS C:\\River\u003e foreach ($item in $School){ Write-Host \"Item index: $($School.IndexOf($item)), Item value: $($item)\" } Item index: 0, Item value: Cindy Candy Mandy Item index: 1, Item value: Chris Green Richard Whooya~~ But what if we add a new year? $year3 = @() $year3 += ‚ÄúJohn‚Äù $year3 += ‚ÄúAlex‚Äù $year3 += ‚ÄúPete‚Äù $School += ,$year3 foreach ($item in $School){ Write-Host ‚ÄúItem index: $($School.IndexOf($item)), Item value: $($item)‚Äù } Item index: 0, Item value: Cindy Candy Mandy Item index: 1, Item value: Chris Green Richard Item index: 2, Item value: John Alex Pete What if we add a new year with more or less members? $year4 = @() $year4 += ‚ÄúMicheal‚Äù $year4 += ‚ÄúBarry‚Äù $year4 += ‚ÄúCharlie‚Äù $year4 += ‚ÄúDoug‚Äù $School += ,$year4 foreach ($item in $School){ Write-Host ‚ÄúItem index: $($School.IndexOf($item)), Item value: $($item)‚Äù } Item index: 0, Item value: Cindy Candy Mandy Item index: 1, Item value: Chris Green Richard Item index: 2, Item value: John Alex Pete Item index: 3, Item value: Micheal Barry Charlie Doug What if we remove a year? $School = $School | ? {$_[0] -ne ‚ÄúCindy‚Äù} The reason why we do this is due to the limitation in PowerShell Array operation. It would be much easier if we use ArrayList. :) Enjoy your coding‚Ä¶ ","date":"2017-06-01","objectID":"/2017-06-01-powershell-multidimensional-arrays-in-powershell/:0:0","tags":["PowerShell","Multidimensional Array"],"title":"PowerShell - Multidimensional Arrays in PowerShell","uri":"/2017-06-01-powershell-multidimensional-arrays-in-powershell/"},{"categories":null,"content":"Working with Consul without UI is the correct way to go, which also help you with the productivity!!! (True?, hahaha~~) Anyway, I‚Äôm not allowed to have a UI for it, come down to have read the correct value and make sure it‚Äôs the one we want it to be in there, I need to do heaps ‚ÄúGet‚Äù to get the value, however the value is encoded with Base64‚Ä¶ Here is the way to decode it: $response = Invoke-RestMethod -Method Get -Uri \"http://localhost:8500/v1/kv/hello\" $b = [System.Convert]::FromBase64String($($response.Value)) [System.Text.Encoding]::UTF8.GetString($b) Hello World To encode it: $b = [System.Text.Encoding]::UTF8.GetBytes(\"Hello World\") [System.Convert]::ToBase64String($b) SGVsbG8gV29ybGQ= Have fun~~ ","date":"2017-02-24","objectID":"/2017-02-24-how-to-convert-string-to-base64-and-vice-versa-using-powershell/:0:0","tags":["PowerShell","Encrpt"],"title":"How to Convert String to Base64 and Vice Versa Using Powershell","uri":"/2017-02-24-how-to-convert-string-to-base64-and-vice-versa-using-powershell/"},{"categories":null,"content":"I need to send a large number (more than 100) emails to my wife for her needs. She has a folder that contains tones pdf files, needs to be send to an email address one file per email. So I created this script to send the mail‚Ä¶ For sure you need to modify this if you are going to send 100 times by using foreach loop‚Ä¶ $smtpserver = \"smtp.telstra.com\" $file = Get-ChildItem -Path \"C:\\temp\\file.pdf\" $sender = Read-Host -Prompt 'Please enter the email you want to send from' $recipient = Read-Host -Prompt 'Please enter the email you want to send to' $msg = New-Object System.Net.Mail.MailMessage if ($file -ne $null) { $att = New-Object System.Net.Mail.Attachment($file.FullName) $msg.Attachments.Add($att) } $smtp = New-Object System.Net.Mail.SmtpClient($smtpserver) $msg.From = $sender $msg.To.Add($recipient) $msg.Subject = \"$file.Name\" $msg.Body = \"It's size is $($file.Length)bytes\" $smtp.Send($msg) Just a hint, have fun~ ","date":"2016-12-11","objectID":"/2016-12-11-send-email-via-powershell/:0:0","tags":["PowerShell","Email"],"title":"Send Email via PowerShell","uri":"/2016-12-11-send-email-via-powershell/"},{"categories":null,"content":"Start playing Terraform ‚Ä¶ Get it downloaded \u0026 saved it to a local folder: C:\\bin Put this path into local $PATH var by running: $env:Path += \";C:\\bin\" Restart a command line, type in terraform: C:\\Users\\River\u003eterraform usage: terraform [--version] [--help] \u003ccommand\u003e [args] The available commands for execution are listed below. The most common, useful commands are shown first, followed by less common or more advanced commands. If you're just getting started with Terraform, stick with the common commands. For the other commands, please read the help and docs before usage. Common commands: apply Builds or changes infrastructure destroy Destroy Terraform-managed infrastructure fmt Rewrites config files to canonical format get Download and install modules for the configuration graph Create a visual graph of Terraform resources import Import existing infrastructure into Terraform init Initializes Terraform configuration from a module output Read an output from a state file plan Generate and show an execution plan push Upload this Terraform module to Atlas to run refresh Update local state file against real resources remote Configure remote state storage show Inspect Terraform state or plan taint Manually mark a resource for recreation untaint Manually unmark a resource as tainted validate Validates the Terraform files version Prints the Terraform version All other commands: state Advanced state management Once you can see above, \"Terraform\" is correctly installed. Due to I only have Azure account, so I‚Äôll start playing with this‚Ä¶ Create a terraform file terraform.tf with following content # Configure the Microsoft Azure Provider provider ‚Äúazurerm‚Äù { subscription_id = ‚Äúsubscription_id‚Äù##Azure Account details, click the ‚Äòsubscription‚Äô, copy the guid id client_id = ‚Äúclient_id‚Äù##Refers to step 3.1 client_secret = ‚Äúclient_secret‚Äù##Refers to step 3.2 tenant_id = ‚Äútenant_id‚Äù##Refers to step 3.3 } Getting above values from Azure need manual work, but once only. Login to Azure legacy portal: https://manage.windowsazure.com Getting ‚Äòclient_id‚Äô, ‚Äòclient_secret‚Äô and ‚Äòtenant_id‚Äô: client_id Select ‚ÄúActive Directory‚Äù Select ‚ÄúApplications‚Äù Select ‚ÄúAdd‚Äù‚Ää‚Äî‚Ää‚ÄúAdd an application my organization is developing‚Äù Give it a good name ‚ÄúTerrabot‚Äù Input any 2 valid URLs, we are not going to consume them at all, so no need to be serious: You can get the client_id from here: client_secret Scroll down to ‚Äòkeys‚Äô secition, select duration Click ‚ÄúSave‚Äù at the bottom of the page, and you can see the key from the same location: tenant_id Click ‚ÄúView Endpoints‚Äù at the bottom of the page: Find ‚ÄúOAUTH 2.0 AUTHORIZATION ENDPOINT‚Äù, and copy the key from the url, you can find it from here: https://login.microsoftonline.com/tenantid/oauth2/authorize Start from a basic resource: # Create a resource group resource \"azurerm_resource_group\" \"au_prod\" { name = \"au_prod\" location = \"Australia East\" } Save the file, and run ‚Äúterraform plan‚Äù: $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. The Terraform execution plan has been generated and is shown below. Resources are shown in alphabetical order for quick scanning. Green resources will be created (or destroyed and then created if an existing resource exists), yellow resources are being changed in-place, and red resources will be destroyed. Cyan entries are data sources to be read. Note: You didn't specify an \"-out\" parameter to save this plan, so when \"apply\" is called, Terraform can't guarantee this is what will execute. + azurerm_resource_group.au_prod location: \"australiaeast\" name: \"au_prod\" Plan: 1 to add, 0 to change, 0 to destroy. Plan shows what will terraform do if run with apply command. We can do terraform apply to get the resource implemented. Here is the simple resource description for 10 servers \u0026 multiple networks: # Configure the Microsoft Azure Provider provider \"azurerm\" { sub","date":"2016-10-12","objectID":"/2016-10-12-terraform-with-azure/:0:0","tags":["Terraform","Azure"],"title":"Terraform with Azure","uri":"/2016-10-12-terraform-with-azure/"},{"categories":null,"content":"I got an issue with vagrant running CentOS as testing environment: $ kitchen create -----\u003e Starting Kitchen (v1.11.1) -----\u003e Creating \u003cdocker-centos72\u003e... Bringing machine 'default' up with 'virtualbox' provider... ==\u003e default: Box 'bento/centos-7.2' could not be found. Attempting to find and install... default: Box Provider: virtualbox default: Box Version: \u003e= 0 ==\u003e default: Loading metadata for box 'bento/centos-7.2' default: URL: https://atlas.hashicorp.com/bento/centos-7.2 ==\u003e default: Adding box 'bento/centos-7.2' (v2.2.9) for provider: virtualbox default: Downloading: https://atlas.hashicorp.com/bento/boxes/centos-7.2/versions/2.2.9/providers/virtualbox.box default: ==\u003e default: Successfully added box 'bento/centos-7.2' (v2.2.9) for 'virtualbox'! ==\u003e default: Preparing master VM for linked clones... default: This is a one time operation. Once the master VM is prepared, default: it will be used as a base for linked clones, making the creation default: of new VMs take milliseconds on a modern system. ==\u003e default: Importing base box 'bento/centos-7.2'... ==\u003e default: Cloning VM... ==\u003e default: Matching MAC address for NAT networking... ==\u003e default: Checking if box 'bento/centos-7.2' is up to date... ==\u003e default: Setting the name of the VM: kitchen-cookbook-didata-tfs-docker-centos72_default_1474595118050_22387 ==\u003e default: Clearing any previously set network interfaces... ==\u003e default: Preparing network interfaces based on configuration... default: Adapter 1: nat default: Adapter 2: hostonly ==\u003e default: Forwarding ports... default: 22 (guest) =\u003e 2222 (host) (adapter 1) ==\u003e default: Booting VM... ==\u003e default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key default: Warning: Remote connection disconnect. Retrying... default: Warning: Remote connection disconnect. Retrying... default: Warning: Remote connection disconnect. Retrying... default: default: Vagrant insecure key detected. Vagrant will automatically replace default: this with a newly generated keypair for better security. default: default: Inserting generated public key within guest... default: Removing insecure key from the guest if it's present... default: Key inserted! Disconnecting and reconnecting using new SSH key... default: Warning: Authentication failure. Retrying... default: Warning: Authentication failure. Retrying... default: Warning: Authentication failure. Retrying... default: Warning: Authentication failure. Retrying... default: Warning: Authentication failure. Retrying... default: Warning: Authentication failure. Retrying... default: Warning: Authentication failure. Retrying... default: Warning: Authentication failure. Retrying... kitchen create is a part of kitchen, which is triggering the vagrant to create a VM by using Virtualbox. The VM was created successfully but we are not able to connect to it with SSH due to the error message: default: Warning: Authentication failure. Retrying... I tested Ubuntu image, it‚Äôs working OK, only for CentOS got issue at the moment. I‚Äôm sure that I remembered that it was working fine before, so I believe this is the issue from vagrant‚Ä¶ By checking the source code for vagrant, this changeset ‚Äú4aaa600‚Äù shows that ‚Äúchmod 600 ~/.ssh/authorized_keys‚Äù is removed from def ‚Äúself.remove_public_key‚Äù. Manually adding this to: Windows: C:\\HashiCorp\\vagrant\\embedded\\gems\\gems\\vagrant-1.8.5\\plugins\\guests\\linux\\cap\\public_key.rb Then check it again: $ kitchen create -----\u003e Starting Kitchen (v1.11.1) -----\u003e Creating \u003cdocker-centos72\u003e... Bringing machine 'default' up with 'virtualbox' provider... ==\u003e default: Cloning VM... ==\u003e default: Matching MAC address for NAT networking... ==\u003e default: Checking if box 'bento/centos-7.2' is up to date... ==\u003e default: Setting the name of the VM: kitchen-cookbook-didata-tfs-docker-centos72_default_1474603585550_53027 ==\u003e default: Fixed port collision for 22 =\u003e 2222. Now on port 22","date":"2016-09-23","objectID":"/2016-09-23-vagrant-with-centos/:0:0","tags":["Vagrant","CentOS"],"title":"Vagrant with CentOS","uri":"/2016-09-23-vagrant-with-centos/"},{"categories":null,"content":"Every language starts with ‚Äúhello world‚Äù, as a DevOps, I‚Äôm going to start with environment~~ Windows 10 (nothing special) Chocolatery https://chocolatey.org/install Python choco install python -y Pycharm https://www.jetbrains.com/pycharm Basic command: # Hello World print(\"Hello World!\") # Variable # Calculation a = 10 b = 50 c = a + b # Print variable name = \"River\" print(\"%sis studying Python.\" % name) # Condition if True: print(\"True\") else: print(\"False\") i = 0 # for Loop for i in range(10): print(i) # while loop while i \u003c 10: print(i) i += 1 #for each loop name_list = ['River', 'Bruno', 'Python'] for name in name_list: print(name) Play with string in bit more advance: name = input(\"Name: \").strip() age = int(input(\"Age: \")) job = input(\"Job: \").strip() msg = ''' Information of %s: Name: %sAge: %dJob: %s''' % (name, name, age, job) print(msg) A basic login design: Login portal Asking for username and password Welcome message if authenticated successfully Lock the account if the authentication failed more than 3 times Multi-level menu 3 levels Select to sub-menu Use ‚ÄúList‚Äù, ‚ÄúDictionary‚Äù # import module import getpass,json,os,datetime # detailed fucntions: def new_locked_account(username): obj_file = open(\"locked.txt\", 'a') obj_file.write(\"%s: %s\" % (username, datetime.datetime.now())) obj_file.write(\"\\n\") def get_locked_account(username): obj_file = open(\"locked.txt\", 'r') read_file = obj_file.read() return (username in read_file) def loginportal_menu(): os.system(\"cls\") print(\"Welcome to the login portal!\") msg = '''Please select from following options: 1: Start Login Portal 0: Return to the main menu''' print(msg) for retry in range(3): option = input(\"Please select 1 or 0: \").strip() if option == '1': loginportal() break elif option == '0': main_menu() break else: print(\"Your input is %s, we are expecting either \\\"1\\\"or \\\"0\\\"\" % option) else: print(\"Too many re-try, please restart the application!\") def loginportal(): db_users = { 'admin': 'admin', 'River': 'python', } username = input(\"Please enter your username: \").strip() if get_locked_account(username): print(\"This account %shas been locked, please contact Administrator!\" % username) exit() db_password = db_users.get(username) for retry in range(3): password = getpass.getpass(prompt='Please enter your password: ') if (db_password is not None) \u0026 (db_password == password): print(\"Authentication successful!\") break else: print(\"Authentication Failed.\") else: print(\"Lock username for %sdue to too many re-try\" % username) new_locked_account(username) def multilevelmenu_menu(): os.system(\"cls\") print(\"Welcome to the multi-level menu demo!\") msg = '''Please select from following options: 1: Start Multi-level menu demo 0: Return to the main menu''' print(msg) for retry in range(3): option = input(\"Please select 1 or 0: \").strip() if option == '1': multilevelmenu() break elif option == '0': main_menu() break else: print(\"Your input is %s, we are expecting either \\\"1\\\"or \\\"0\\\"\" % option) else: print(\"Too many re-try, please restart the application!\") def member_list(menudata_team): teamdata = menudata_team['Members'] for i in range(len(teamdata)): print(\"%s: %s\" % (i + 1, teamdata[i])) print(\"0: Return to the previous menu\") int_menuselect = None while (type(int_menuselect) is not int): menuselect = input(\"Please select 0 to return or other number keys to exit:\") try: int_menuselect = int(menuselect) except ValueError: # handle if input cannot be converted to int int_menuselect = None if (type(int_menuselect) is int): break print(\"Your input is %s, we are expecting only above numbers.\" % menuselect) if int_menuselect == 0: multilevelmenu() def team_list(menudata_group): options = { 0: group_list, } groupdata = menudata_group['Teams'] for i in range(len(groupdata)): print(\"%s: %s\" % (i + 1, groupdata[i]['TeamName'])) options[i + 1] = member_list print(\"0: Return to the previous menu\") int_menuselect = None while (int_menuselect not in range(len(groupdata) + 1)) | (type(int_menu","date":"2016-09-15","objectID":"/2016-09-15-python-starting/:0:0","tags":["Python"],"title":"Python Starting","uri":"/2016-09-15-python-starting/"},{"categories":null,"content":"While playing with UCS PowerShell command to adjust initial environment configuration‚Ä¶ There are a lot of things that not following the ‚Äúrule‚Äù Here is the JSON for an Object: { \"BootMode\":\"legacy\", \"Descr\":\"\", \"EnforceVnicName\":\"yes\", \"Name\":\"BuildBootPolicy\", \"PolicyLevel\":0, \"PolicyOwner\":\"local\", \"PropAcl\":0, \"Purpose\":\"operational\", \"RebootOnUpdate\":\"no\", \"Sacl\":null, \"Ucs\":\"ucsmanager\", \"Dn\":\"org-root/boot-policy-BuildBootPolicy\", \"Rn\":\"boot-policy-BuildBootPolicy\", \"Status\":null, \"XtraProperty\":{ }, \"BootPolicyConfiguration\":{ \"read-only-remote-cimc-vm\":{ \"Access\":\"read-only-remote-cimc\", \"LunId\":\"0\", \"MappingName\":\"\", \"Order\":1, \"PropAcl\":0, \"Sacl\":null, \"Type\":\"virtual-media\", \"Ucs\":\"ucsmanager\", \"Dn\":\"org-root/boot-policy-BuildBootPolicy/read-only-remote-cimc-vm\", \"Rn\":\"read-only-remote-cimc-vm\", \"Status\":null, \"XtraProperty\":{ }, \"ClassId\":\"LsbootVirtualMedia\" }, \"storage\":{ \"Access\":\"read-write\", \"Order\":2, \"PropAcl\":0, \"Sacl\":null, \"Type\":\"storage\", \"Ucs\":\"ucsmanager\", \"Dn\":\"org-root/boot-policy-BuildBootPolicy/storage\", \"Rn\":\"storage\", \"Status\":null, \"XtraProperty\":{ }, \"ClassId\":\"LsbootStorage\" } } } The structure of this object: BootPolicy BootPolicyConfiguration Boot device order When I‚Äôm trying to add the first boot device order object, following command should be run: Add-UcsCentralManagedObject -Parent $UCSCentralBootPolicy -ClassId LsbootVirtualMedia -PropertyMap @{Access=\"read-only-remote-cimc\";LunId=0;Order=1} This command will pass the PropertyMap as hastable: Access LunId Order But when I‚Äôm running the second boot device order object, if I still running the similar command based on the previous one: Add-UcsCentralManagedObject -Parent $UCSCentralBootPolicy -ClassId LsBootStorage -PropertyMap @{Access=\"read-write\";Order=2} It will trough the error message as Looks like the ‚ÄúAccess‚Äù is a read-only property that cannot be set for this object, looks like they are not set in standard by Cisco PowerShell API Developer. We need to find a way to detect when we need this property and when we don‚Äôt. By using decompiler ILSpy to check the DLL file (Cisco.UcsCentral.dll), find the class called LsbootVirtualMedia, we can see: But with LsBootStorage In PowerShell, we can use following method to check this property is writable or not: We need a more dynamic way as different object has different properties but in the same collection as a part of the Configuration. So we need do this: $sc = \"Cisco.UcsCentral.$ClassId\" -as [type] Then we can call following to find the property value we need: $sc::AccessMeta.Access So good luck to my long journey for UCS Automation‚Ä¶ River ","date":"2016-07-16","objectID":"/2016-07-16-powershellcheck-class-properties-ucs-as-example/:0:0","tags":["PowerShell","UCS"],"title":"PowerShell ‚Äî Check Class Properties (UCS as Example)","uri":"/2016-07-16-powershellcheck-class-properties-ucs-as-example/"},{"categories":null,"content":"When removing a folder, and it complains the files in the folder are in used, how to ignore the error and force them to be removed? function KillProcessesWithHandles { param([string]$path) $allProcesses = Get-Process # Start by closing all notepad processes. Someone may have left a logor config file open $allProcesses | where {$_.Name -eq \"notepad\"} | Stop-Process -Force -ErrorAction SilentlyContinue # Then close all processes running inside the folder we are trying to delete $allProcesses | where {$_.Path -like ($path + \"*\")} | Stop-Process -Force -ErrorAction SilentlyContinue # Finally close all processes with modules loaded from folder we are trying to delete foreach($lockedFile in Get-ChildItem -Path $path -Include * -Recurse) { foreach ($process in $allProcesses) { $process.Modules | where {$_.FileName -eq $lockedFile} | Stop-Process -Force -ErrorAction SilentlyContinue } } } Terminate notepad process Terminate any relevant process that may using that file Terminate any process that is loading that file‚Ä¶ Only use this on your own risk Happy scripting. :) ","date":"2016-03-17","objectID":"/2016-03-17-delete-content-of-folder-containig-files-with-open-file-handles-using-powershell/:0:0","tags":["PowerShell"],"title":"Delete Content of folder Containig Files With Open File Handles Using Powershell","uri":"/2016-03-17-delete-content-of-folder-containig-files-with-open-file-handles-using-powershell/"},{"categories":null,"content":"Well, this is quite a dirty fix for anything not stable‚Ä¶ First time failed? Run second time, failed? Third time again‚Ä¶ Only exits successful or retried more than 3 times. $Stoploop = $false [int]$Retrycount = \"0\" do { try { Scripts Commands here Write-Host \"Job completed\" $Stoploop = $true } catch { if ($Retrycount -gt 3){ Write-Host \"Could not send Information after 3 retrys.\" $Stoploop = $true } else { Write-Host \"Could not send Information retrying in 30 seconds...\" Start-Sleep -Seconds 30 $Retrycount = $Retrycount + 1 } } } While ($Stoploop -eq $false) ","date":"2016-02-24","objectID":"/2016-02-24-powershell-simple-retry-logic/:0:0","tags":["PowerShell"],"title":"PowerShell Simple Retry Logic","uri":"/2016-02-24-powershell-simple-retry-logic/"},{"categories":null,"content":"I don‚Äôt know how to Crack the current local admin password, but I know how to reset or become one. :) Following tools is all you need: Ability to Insert CD (ISO) to the VM (Server) Ability to boot VM (Server) from CD Windows Installation CD (ISO), 2012R2, 2012, Win7, 2008R2, 2008, etc‚Ä¶ all good Steps: Shutdown the Server (VM) Insert windows installation CD (ISO) to the Server (VM) Boot up the Server (VM) from CD When you see the welcome installation page, press ‚ÄúShift + F10‚Äù Backup ‚Äúosk.exe‚Äù move C:\\windows\\system32\\osk.exe c:\\windows\\system32\\osk.bak Copy ‚Äúcmd.exe‚Äù as ‚Äúosk.exe‚Äù copy C:\\windows\\system32\\cmd.exe c:\\windows\\system32\\osk.exe Eject CD (ISO) Reboot the server At the login page, click On-Screen Keyboard, you will see command prompt popped up‚Ä¶ :) Now, you have two options: Add a new user: Username: tempadmin Password: password, and add it into local admin group net user tempadmin password /add net localgroup ‚Äúadministrators‚Äù ‚Äútempadmin‚Äù /add Reset existing administrator‚Äôs password: Assume ‚ÄúAdministrator‚Äù is the local admin, and we are resetting its password to ‚ÄúP@ssw0rd‚Äù net user administrator P@ssw0rd Then quit this command prompt You are good to login with your new username and password as administrator. Just don‚Äôt forget to copy the osk.bak back to osk.exe and delete the tempadmin user if you created after you fix your local admin password! Enjoy! ","date":"2016-02-18","objectID":"/2016-02-18-forgot-windows-local-admin-password-lets-get-it-reset-or-create-a-new-one/:0:0","tags":["Crack","password","Windows","Admin"],"title":"Forgot Windows Local Admin Password? Let's Get it Reset or Create a New One!","uri":"/2016-02-18-forgot-windows-local-admin-password-lets-get-it-reset-or-create-a-new-one/"},{"categories":null,"content":"As NetBIOS is a legacy technology and should be replaced by DNS in LAN, we are deciding to disable all NetBIOS on all NICs in our environment. However, we saw the issue straightaway: All AG SQL Cluster services are stopped‚Ä¶ Error message normally like: Event ID: 1205: The Cluster service failed to bring clustered service or application ‚ÄòAGName‚Äô completely online or offline. One or more resources may be in a failed state. This may impact the availability of the clustered service or application. Event ID: 1069: Cluster resource ‚ÄòAG Network Resource Name‚Äô of type ‚ÄòNetwork Name‚Äô in clustered role ‚ÄòAGName‚Äô failed. Based on the failure policies for the resource and role, the cluster service may try to bring the resource online on this node or move the group to another node of the cluster and then restart it. Check the resource and group state using Failover Cluster Manager or the Get-ClusterResource Windows PowerShell cmdlet. We are able to bring the IP online, but not the resource itself (same pic shows above). It shows that‚Äôs the Network Resource issue, and it‚Äôs complaining about the Name cannot be registered with DNS. By checking the properties of NIC, I found the NIC has NetBIOS disabled, which is what I want, but SQL AG Network IP Address has it enabled‚Ä¶ The way to fix it: Clear the checkbox of Enable NetBIOS for this address in IP Address Property: Problem fixed! :) ","date":"2015-12-09","objectID":"/2015-12-09-netbios-impacts-cluster-service/:0:0","tags":["NetBIOS","Windows","Cluster"],"title":"NetBIOS Impacts Cluster Service","uri":"/2015-12-09-netbios-impacts-cluster-service/"},{"categories":null,"content":"Previous Post indicates that we are able to do one way copy files from HOST level to VM itself in Windows. We are able to do the same thing in Linux too. :) I don‚Äôt have Ubuntu, so I didn‚Äôt got chance to test, but for Red Hat or CentOS: On Linux Guest VM: yum -y install hyperv-daemons On Hyper-V Host or PowerShell remote session: Enable-VMIntegrationService -ComputerName $VM.VMHost -VMName $VM.Name -Name ‚ÄúGuest Service Interface‚Äù On Linux Guest VM: reboot On Hyper-V Host or PowerShell Remote Session: Get-VMIntegrationService -ComputerName $VM.VMHost -VMName $VM.Name -Name ‚ÄúGuest Service Interface‚Äù We should be able to see that the Guest Service Interface is enable and the status is OK to communicate with the HOST, if not, check the service called hypervfcopyd is running or not on Linux Guest VM Finally, we are able to use following command to do the file copy: Copy-VMFile -ComputerName $VM.VMHost -VMName $VM.Name -SourcePath ‚ÄúD:\\Test.txt‚Äù -DestinationPath ‚Äú/etc/folder‚Äù -CreateFullPath -FileSource Host But note here, Linux command is bit different from Windows, In windows we use file name as the Source and Destination in the same way. But this doesn‚Äôt work in Linux. In Linux, we use file name as the source and we use the folder that should contains the file as the destination Path. Enjoy your magic script without Network Connection! ","date":"2015-11-13","objectID":"/2015-11-13-powershell-linux-server-file-injection-via-hypervisor/:0:0","tags":["tagA","tagB"],"title":"PowerShell Linux Server File Injection via Hypervisor","uri":"/2015-11-13-powershell-linux-server-file-injection-via-hypervisor/"},{"categories":null,"content":"When you got 2 NIC on the same VM, one is Internal NIC, another is External NIC: Internal: 172.23.0.0/24 External: 172.20.0.0/16 When you are trying to talk to out side of any of these 2 subnet, for example: 172.21.0.0, 10.52.0.0, etc‚Ä¶ The correct NIC the traffic should go through is via External. But somehow, you might be see this when you do route print: We can see there are Double 0.0.0.0 entries with same metric value as default gateway. We need to do 2 things: route ‚Äìf ‚Äìp -4 add 0.0.0.0 mask 0.0.0.0 172.20.0.1 metric 5 This will clear all existing gateway information but only the one we added shutdown /r /t 10 restart the computer in 10 seconds, enough time for the script to be renamed, this will help to rebuild the route table Make sure run this as a batch cmd, because you will lost connectivity if you are in the RDP session‚Ä¶ Enjoy scripting‚Ä¶ ","date":"2015-11-13","objectID":"/2015-11-13-batch-windows-network-gateway-configuration/:0:0","tags":["Windows Server","tagB"],"title":"Batch - Windows Network Gateway Configuration","uri":"/2015-11-13-batch-windows-network-gateway-configuration/"},{"categories":null,"content":"If there is a way that we can manage our VMs from the hyper-visor level, like invoke command from HOST directly to VM, that would be awesome!!!! However, the method is only available from Windows 10/Server 2016 called: PowerShell Direct For the current users who is running on Windows Server 2012 \u0026 Windows Server 2012R2, we can use following trick to get it work. We will following resource to get this done: An AD account with enough permission Hyper-V admin Run Administration PowerShell script from the Hyper-V host Login the VM: Open up Schedule Task, create a new task by using the previous AD Account Run this task every 5 mins \u003c- Can be any time interval you want. Action: run a PowerShell script ‚ÄúC:\\Script\\ScheduledPowerShellCaller.ps1‚Äù to call another script (Script content will be provided later) Program File: C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe Argument: -File C:\\scripts\\ScheduledPowerShellCaller.ps1 ScheduledPowerShellCaller.ps1: $RemoteCMDPath = \"C:\\scripts\\RemoteCMD.ps1\" if(Test-Path $RemoteCMDPath) { . $RemoteCMDPath Remove-Item $RemoteCMDPath } The way to call it: Create a new script: RemoteCMD.ps1 New-Item -Path C:\\testfolder$((Get-Date).ToString(‚ÄúHHmmss‚Äù)) -ItemType Directory Copy the file into VM by using Copy-VMFile: Copy-VMFile -VM $VM -SourcePath C:\\Scripts\\RemoteCMD.ps1 -DestinationPath C:\\Scripts\\RemoteCMD.ps1 -FileSource Host Check the VM‚Äôs C Drive see the change in 5 mins. New folder is created automatically, and the RemoteCMD.ps1 is gone to prevent it‚Äôs running again :) ","date":"2015-10-31","objectID":"/2015-10-31-powershell-hyper-v-vm-management-tip/:0:0","tags":["PowerShell","Hyper-V"],"title":"PowerShell Hyper-V VM Management Tip","uri":"/2015-10-31-powershell-hyper-v-vm-management-tip/"},{"categories":null,"content":"We got an issue for TFS build server today, it doesn‚Äôt build anything. Symptoms From Visual Studio, we cannot see any progress for the build. From the build server, we cannot see any build being triggered, all agents status are ‚ÄúReady‚Äù. Investigation: Check the connectvity between Client to TFS Web Service‚Ää‚Äî‚ÄäOK Check the connectivity between TFS Web Server to TFS Build Server‚Ää‚Äî‚ÄäOK Check the connectivity between Client to TFS Build Server‚Ää‚Äî‚ÄäOK Restart the TFS Build Controller‚Ää‚Äî‚ÄäStill not working Restart the TFS Build Server‚Ää‚Äî‚ÄäStill not working Check the event log on TFS Build Server Applications and Services Logs -\u003e Microsoft -\u003e Team Foundation Server -\u003e Build-Services -\u003e Operational There are few ‚ÄúCritical‚Äù Error message: Default Controller‚Ää‚Äî‚Ää[BuildServerName]: Failed to update build vstfs:///Build/Build/[BuildNumber] on server https://[tfs Collection] due to invalid permission configuration. Follow by the ‚ÄúCritical‚Äù Error, we have another ‚ÄúError‚Äù: Default Controller‚Ää‚Äî‚Ää[BuildServerName]: Failed to finalize build vstfs:///Build/Build/[BuildNumber] due to an exception. Exception Type: Microsoft.TeamFoundation.Build.Client.AccessDeniedException Exception Message: TF215106: Access denied. [An AD Account] needs Update build information permissions for build definition [Build Defination Name] in team project [Project Name] to perform the action. For more information, contact the Team Foundation Server administrator. Stack Trace: at Microsoft.TeamFoundation.Client.Channels.TfsHttpClientBase.HandleReply(TfsClientOperation operation, TfsMessage message, Object[]\u0026 outputs) at Microsoft.TeamFoundation.Build.Client.BuildWebService4.UpdateBuildInformation(InformationChangeRequest[] changes) at Microsoft.TeamFoundation.Build.Client.InformationNodeConverters.BulkUpdateInformationNodes(BuildDetail build, List`1 requests) at Microsoft.TeamFoundation.Build.Client.BuildInformation.Save() at Microsoft.TeamFoundation.Build.Hosting.BuildControllerWorkflowManager.FlushBuild(IBuildDetail build, BuildStatus finalStatus) at Microsoft.TeamFoundation.Build.Hosting.BuildControllerWorkflowManager.OnInstanceCompleted(BuildWorkflowInstance instance, IDictionary`2 outputs, Exception terminationException) From my understanding, the workflow for triggering a build should be: User Trigger a build in Visual Studio Visual Studio requests the job by using TFS Web Service TFS Web Service will create entry in TFS DB, and communicate the TFS Build Server to build. (Not sure if this is correct or not) TFS Build Server will need to talk back to TFS Web Service Server to update TFS DB for the Build information TFS Build Server will need to give the job to one of the build agents and build the solution‚Ä¶ Based on the error message we found there, I think the root cause is on 4, because the AD Account doesn‚Äôt have permission to to update the build information from Build Server But we never had this problem before by using this service account, and it should have all admin permission for TFS. By chekcing the permission setup in TFS, I‚Äôve confirmed this account doesn‚Äôt have any problem with security settings. Secondly, I tried use this service account to login to TFS Web Service, it didn‚Äôt work saying permission issue. Finally, the wrong credential was found in Credential manager, There is a record hard coded for TFS Web Service address with the AD account mentioned above. After removing the record, everything comes back online. :)","date":"2015-09-23","objectID":"/2015-09-23-tfs-build-server-stops-workingpermission-issue/:0:1","tags":["TFS","Windows"],"title":"TFS Build Server Stops Working - Permission Issue","uri":"/2015-09-23-tfs-build-server-stops-workingpermission-issue/"},{"categories":null,"content":"We got the Container, then we will need to used it for our application via Network. ","date":"2015-09-15","objectID":"/2015-09-15-windows-docker-basic-networking/:1:0","tags":["Windows Docker","Networking"],"title":"Windows Docker Basic Networking","uri":"/2015-09-15-windows-docker-basic-networking/"},{"categories":null,"content":"Creating network for our Container now: No matter what, we need to create a Virtual Switch on Container HOST $VMSwitch = Get-VMSwitch if ($VMSwitch.Count -le 0) { #Creating a VMSwitch New-VMSwitch -Name ‚ÄúVirtual Switch‚Äù -SwitchType NAT -NATSubnetAddress ‚Äú172.16.0.0/12‚Äù } Create a NAT #Creating a Net Nat New-NetNat -Name ContainerNAT -InternalIPInterfaceAddressPrefix ‚Äú172.16.0.0/12‚Äù Create a container with this Switch $IISContainer = New-Container -Name IISContainer -ContainerImage $containerImage -SwitchName ‚ÄúVirtual Switch‚Äù ","date":"2015-09-15","objectID":"/2015-09-15-windows-docker-basic-networking/:1:1","tags":["Windows Docker","Networking"],"title":"Windows Docker Basic Networking","uri":"/2015-09-15-windows-docker-basic-networking/"},{"categories":null,"content":"Start this Container and get Web-Server windows feature installed Install-WindowsFeature -Name Web-Server Map Container HOST and Container itself with TCP port 80 Add-NetNatStaticMapping -NatName ContainerNat -Protocol TCP -ExternalIPAddress 0.0.0.0 -InternalIPAddress 172.16.0.2 -InternalPort 80 -ExternalPort 80 Allow firewall on 80 port New-NetFirewallRule -Name ‚ÄúWeb Server‚Äù -DisplayName ‚ÄúHTTP on TCP/80‚Äù -Protocol tcp -LocalPort 80 -Action Allow -Enabled true Now, we are able to access the default website from another computer in the network. :) ","date":"2015-09-15","objectID":"/2015-09-15-windows-docker-basic-networking/:1:2","tags":["Windows Docker","Networking"],"title":"Windows Docker Basic Networking","uri":"/2015-09-15-windows-docker-basic-networking/"},{"categories":null,"content":"As we want to use Docker‚Äôs Container technology to help us fast deployment, but how fast it is? Let‚Äôs do a quick count here: Create a brand new Container Start up the Container Enter into its session Remove the Container Let‚Äôs see how it goes: Create a brand new Container, 2 seconds, not bad, how fast you can create a new VHD disk which contains a OS? $containerImage = Get-ContainerImage -Name WindowsServerCore Measure-Command {$testContainer = New-Container -Name testContainer -ContainerImage $containerImage} Start up the Container, almost 8 seconds to get a fully boot OS, how fast does your SSD give your an OS from the moment while you press the power button? Measure-Command {Start-Container -Container $testContainer} Enter to Container‚Äôs Session, 6 seconds to get into the Container‚Äôs session, which is similar as normal speed to remote manage other computer. But, don‚Äôt forget this is a new machine that it‚Äôs not joined the domain, so it‚Äôs using local authentication‚Ä¶ Measure-Command {Enter-PSSession -ContainerId $testContainer.ContainerId -RunAsAdministrator} Stop the Container then remove it. Total 15 seconds. Measure-Command {Stop-Container $testContainer;Remove-Container $testContainer -Confirm: $false -Force} Generally, it looks pretty good. As long as we prepared the Image well, with docker build file, we will get much better deployment experience I believe. :) Then we might want to know how it goes with Hardware consumption (Mostly it‚Äôs memory) compare to the VM. The current VM I‚Äôm running is using 795MB Memory. During the creation of a new Container, it increased to 810MB due to Container Service got started. Start creating the 2nd Container, the memory usage didn‚Äôt change too much, around 815MB. Startup one of the container, memory usage increased to 930MB, ‚ÄúCExecSvc.exe‚Äù started with session ID = 3 Startup the 2nd one, memory usage increased to 1GB, about 70MB different from last state, 2nd ‚ÄúCExecSvc.exe‚Äù started with session ID = 4 Stop all Containers, memory dropped back to 830MB. all ‚ÄúCExecSvc.exe‚Äù terminated Remove all Containers, memory didn‚Äôt change. From this basic test, we can see an Container OS initialized with around 100MB memory usage, and it will only increase if it uses more resources. In order to use Container in the real world, we need to bring network feature in to let it run some applications. :) Will introduce this in the next blog. ","date":"2015-09-13","objectID":"/2015-09-13-windows-docker-basic-performance/:0:0","tags":["Windows Docker","Windows Server 2016"],"title":"Windows Docker Basic Performance","uri":"/2015-09-13-windows-docker-basic-performance/"},{"categories":null,"content":"We‚Äôve installed the WIM for the Container base Image, then we can see it from: Get-ContainerImage Here, we will do following: Use ‚ÄúWindowsServerCore‚Äù base Image to create a Container Start the Container Enter into the Container Read some basic information Make changes on folder and files Mark around with Registry Windows feature install or removal Exit from the Container Stop the Container Start it again Check values Stop and remove There was something stupid I did for this Lab: I deleted system files, a lot‚Ä¶. and trying to install Windows Feature IIS and didn‚Äôt get successful. So I have to use a new Container to do the demo, that‚Äôs why you can see the Container ID is different from previous pic. So please be careful when you are trying delete system files. :) Hopefully this will give you an idea about what container is and why do we need it‚Ä¶ We are creating a new Container by using the Container base Image: #Get the Container Image $containerImage = Get-ContainerImage -Name WindowsServerCore #Create the Container $testContainer = New-Container -Name testContainer -ContainerImage $containerImage Check the Container‚Äôs state Get-Container Start the Container Start-Container -Container $testContainer Check the Container‚Äôs state again Get-Container Enter into the Container with default user Enter-PSSession -ContainerId $testContainer.ContainerId #find out current running user whoami Enter as Admin Enter-PSSession -ContainerId $testContainer.ContainerId -RunAsAdministrator #find out current running user whoami Get some basic information inside and outside of this Container (Do compare) #Get the Container‚Äôs Computername $env:computername #Get the Container Host‚Äôs Computername \u003c- Don‚Äôt know if this is a bug for now [System.Net.Dns]::GetHostName() #Get PS Information $PSVersionTable #Get Windows Feature status for Web Server Get-WindowsFeature ‚ÄúWeb-Server‚Äù #Get PS Drive Providers Get-PSDrive #Get Network information ipconfig Running inside of the container: Running out of the container: Simply delete some random files‚Ä¶ or make some random folders in C: You will find the file system is totally seperated between host and container Delete heaps things in HKLM:\\Software: rm HKLM:\\SOFTWARE -Recurse -Force Same as above, the registry is totally seperated as well Install IIS feature in Container Exit Container -\u003e Exit Stop Container Stop-Container $testContainer Start Container again, Check the value Remove Container Stop-Container $testContainer Remove-Container $testContainer -Confirm: $false -Force Get-Container This is the basic operation for Container in Windows. As you can see, it‚Äôs a application level virtualisation technology. Next time, I‚Äôll do some basic performance test to show how quickly we can bring up an application. :) ","date":"2015-09-12","objectID":"/2015-09-12-windows-docker-first-run-a-container/:0:0","tags":["Windows Server 2016","Windows Docker","Docker"],"title":"Windows Docker - First Run a Container","uri":"/2015-09-12-windows-docker-first-run-a-container/"},{"categories":null,"content":"In order to get docker container working, we need the base image for any customization or modification. Firstly, get the WIM file ready: CBaseOs_th2_release_10514.0.150808‚Äì1529_amd64fre_ServerDatacenterCore_en-us.wim This can be downloaded from MSDN. Open up my favorite PowerShell ISE, check current Container status: #Check Current Container Get-Container #Check Current Container Image Get-ContainerImage #Check Container Host Get-ContainerHost As we can see, we got null value from the first two command due to we have nothing to run for Container, and following is the result for our Container HOST: Name ContainerImageRepositoryLocation ---- -------------------------------- DOCKER01-GUI C:\\ProgramData\\Microsoft\\Windows\\Hyper-V\\Container Image Store Let‚Äôs check all cmdlet for Container in Windows: Get-Command *Container* There are 2 similar commands relates to create a new Container Image: Install-ContainerOSImage Import-ContainerImage By using ‚ÄúGet-Help‚Äù, we know that we should use ‚ÄúInstall-ContainerOSImage‚Äù to Installs a base image from a WIM file into the shared central image store for the Windows Server and Hyper-V Containers feature. So, we are running below: Install-ContainerOSImage -WimPath \"C:\\WIM\\CBaseOs_th2_release_10514.0.150808-1529_amd64fre_ServerDatacenterCore_en-us.wim\" Then we get following: It looks good, isn‚Äôt it? A snapshot will be taken after this, because next step will be bit mass, if you want to try different things, you may want to do the same as me. :) ","date":"2015-09-12","objectID":"/2015-09-12-windows-docker-docker-image-preparation/:0:0","tags":["Windows Server 2016","Windows Docker","Docker"],"title":"Windows Docker - Docker Image Preparation","uri":"/2015-09-12-windows-docker-docker-image-preparation/"},{"categories":null,"content":"Got several times script running failed due to the ISE or PowerShell didn‚Äôt run as Administrator. Uhmm, trying to show it as log or debug warning for this‚Ä¶ In order to make sure we are running the script as Administrator, we can use following script to test whether we are going to run this or not: function Test-RunAsAdmin() { # Get the ID and security principal of the current user account $myWindowsID=[System.Security.Principal.WindowsIdentity]::GetCurrent() $myWindowsPrincipal=new-object System.Security.Principal.WindowsPrincipal($myWindowsID) # Get the security principal for the Administrator role $adminRole=[System.Security.Principal.WindowsBuiltInRole]::Administrator # Check to see if we are currently running \"as Administrator\" if ($myWindowsPrincipal.IsInRole($adminRole)) { $global:AdminPriviledges = $true return $true } else { # # We are not running \"as Administrator\" # Exit from the current, unelevated, process # throw \"You must run this script as administrator\" return $false } } Enjoy Scripting~~ ","date":"2015-09-12","objectID":"/2015-09-12-test-runasadmin-powershell/:0:0","tags":["PowerShell","RunAsAdmin"],"title":"Test RunAsAdmin PowerShell","uri":"/2015-09-12-test-runasadmin-powershell/"},{"categories":null,"content":"Is there any different between the result of ‚ÄúHostname‚Äù \u0026 ‚Äú$env:ComputerName‚Äù ? Before Windows Server 2016, I was thinking that they are not the same is because of following: hostname is a exe wrapper from MS, it returns full computer name, even it‚Äôs more than 15 characters. $env:computername is a var in PowerShell, it returns NetBIOSComputername which is limited in 15 characters But today, I‚Äôm so wrong‚Ä¶. Environment: Container Host: Docker01-Gui Container name: \u003c Random \u003e By using following command: Write-Host '$env:computername:' $env:computername $hostname = hostname Write-Host 'hostname.exe:' $hostname $w32compsys = Get-WMIObject Win32_ComputerSystem | Select-Object -ExpandProperty name Write-Host 'Get-WMIObject Win32_ComputerSystem | Select-Object -ExpandProperty name:' $w32compsys Write-Host '(Get-CIMInstance CIM_ComputerSystem).Name:' (Get-CIMInstance CIM_ComputerSystem).Name $machinename = [system.environment]::MachineName Write-Host '[system.environment]::MachineName:' $machinename $dnsname = [System.Net.Dns]::GetHostName() Write-Host '[System.Net.Dns]::GetHostName():' $dnsname We got result in Container Host: $env:computername: DOCKER01-GUI hostname.exe: Docker01-Gui Get-WMIObject Win32_ComputerSystem | Select-Object -ExpandProperty name: DOCKER01-GUI (Get-CIMInstance CIM_ComputerSystem).Name: DOCKER01-GUI [system.environment]::MachineName: DOCKER01-GUI [System.Net.Dns]::GetHostName(): Docker01-Gui We got result in Container itself: $env:computername: WIN-E2ABUUD2V1V hostname.exe: Docker01-Gui Get-WMIObject Win32_ComputerSystem | Select-Object -ExpandProperty name: WIN-E2ABUUD2V1V (Get-CIMInstance CIM_ComputerSystem).Name: WIN-E2ABUUD2V1V [system.environment]::MachineName: WIN-E2ABUUD2V1V [System.Net.Dns]::GetHostName(): Docker01-Gui As we can see above, ‚Äúhostname.exe‚Äù and ‚Äú[System.Net.Dns]::GetHostName()‚Äù are returning Container Host‚Äôname which is not the real value I think it should be‚Ä¶ I‚Äôm not sure if this is the expected value or a bug, but anyway, I‚Äôm going to use $env:computername to retrieve the local logic physic host in the future. How about you? ","date":"2015-09-12","objectID":"/2015-09-12-hostname-computername-i-am-wrong/:0:0","tags":["Windows Server 2016","Windows Docker","Docker"],"title":"HostName = ComputerName? I Am Wrong!","uri":"/2015-09-12-hostname-computername-i-am-wrong/"},{"categories":null,"content":"We finished the OS installation earlier, now‚Ä¶ Let‚Äôs start Configuring OS: Change Computer Name Add Feature to enable Container Network Settings: Static IP I‚Äôll try to make all above from PowerShell, so we only need to maintain the script rather than a document. :) Get-WindowsFeature -Name Containers | Install-WindowsFeature $IPAddress = \"192.168.100.150\" $LocalConnection = Get-NetIPAddress -InterfaceAlias \"Ethernet\" -AddressFamily IPv4 New-NetIPAddress -IPAddress $IPAddress -InterfaceIndex $LocalConnection.InterfaceIndex -AddressFamily IPv4 -PrefixLength 24 -DefaultGateway \"192.168.100.254\" Set-DnsClientServerAddress -InterfaceIndex $LocalConnection.InterfaceIndex -ServerAddresses \"192.168.100.254\",\"8.8.8.8\" $NewComputerName = \"Docker01-Gui\" Rename-Computer -NewName $NewComputerName -Restart Windows Server 2016 will restarted with: New Feature ‚ÄúContainers‚Äù installed New Computer name as ‚ÄúDocker01-Gui‚Äù New IP: 192.168.100.150 with DNS 192.168.100.254 Let‚Äôs check if all Configuration correct or wrong: We can start next Configuration for Docker. Before doing that, I‚Äôd like to take snapshot first‚Ä¶ :) ","date":"2015-09-11","objectID":"/2015-09-11-windows-docker-os-configuration/:0:0","tags":["Windows Docker","Docker","Windows Server 2016"],"title":"Windows Docker Os Configuration","uri":"/2015-09-11-windows-docker-os-configuration/"},{"categories":null,"content":"Docker container running on Windows? As a MS fans, I‚Äôd like to try heaps things different. Docker, as the newest thing come out of the market for Windows, it‚Äôs a must try! Prepare OS‚Äôs ISO: can be downloaded from MSDN site WIM used for Docker OS base: can be downloaded from MSDN site OK, Let‚Äôs get the system installed first‚Ä¶ nothing special, boot as ISO, next, next, next‚Ä¶done! This is the first see for Windows 2016: My best love: PowerShell ISE That‚Äôs all we have here for this one. Next, we will do some customization for OS‚Ä¶ ","date":"2015-09-11","objectID":"/2015-09-11-windows-docker-os-installation/:0:0","tags":["Windows Docker","Docker","Windows Server 2016"],"title":"Windows Docker Os Installation","uri":"/2015-09-11-windows-docker-os-installation/"},{"categories":null,"content":"PowerShell cmdlet with proxy? - Well, this is for Windows User‚Ä¶ Sometimes you will need to work in a company that has a Proxy Server configured for security reason‚Ä¶ I know it‚Äôs bit annoying. Especially when I‚Äôm trying to connect my Azure Account: Add-AzureAccount -Credential (Get-Credential) Then I got: PS C:\\Users\\ryang\u003e Add-AzureAccount -Credential (Get-Credential) cmdlet Get-Credential at command pipeline position 1 Supply values for the following parameters: Add-AzureAccount : user_realm_discovery_failed: User realm discovery failed: The remote server returned an error: (407) Proxy Authentication Required. At line:1 char:1 + Add-AzureAccount -Credential (Get-Credential) + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : CloseError: (:) [Add-AzureAccount], AadAuthenticationFailedException + FullyQualifiedErrorId : Microsoft.WindowsAzure.Commands.Profile.AddAzureAccount Proxy Authentication‚Ä¶ ah‚Ä¶ By checking the winHTTP settings: PS C:\\Users\\ryang\u003e netsh winhttp show proxy Current WinHTTP proxy settings: Direct access (no proxy server). All we need to do is: Tell PowerShell using the same Proxy Setting as IE Pass my current Credential to Proxy Firstly‚Ä¶ netsh winhttp import proxy source=ie Then with the Credential‚Ä¶ $webclient=New-Object System.Net.WebClient $webclient.Proxy.Credentials= Get-Credential Try it again‚Ä¶. ","date":"2015-09-08","objectID":"/2015-09-08-powershell-working-behind-a-proxy-with-authentication/:0:0","tags":["PowerShell","Proxy"],"title":"Powershell Working Behind a Proxy With Authentication","uri":"/2015-09-08-powershell-working-behind-a-proxy-with-authentication/"}]